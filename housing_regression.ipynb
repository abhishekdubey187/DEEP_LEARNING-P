{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#import pandas as pd\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "\n",
        "# scaling and train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# creating a model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# evaluation on test data\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('Housing.csv')\n",
        "\n",
        "\n",
        "print(df.columns.values)\n",
        "# preview the data\n",
        "df.head()\n",
        "\n",
        "# No missing values\n",
        "df.isnull().sum()\n",
        "\n",
        "df.info()\n",
        "\n",
        "df = df.drop('id', axis=1)\n",
        "df = df.drop('zipcode',axis=1)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "df['month'] = df['date'].apply(lambda date:date.month)\n",
        "df['year'] = df['date'].apply(lambda date:date.year)\n",
        "\n",
        "df = df.drop('date',axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# Check the new columns\n",
        "print(df.columns.values)\n",
        "# Features\n",
        "X = df.drop('price',axis=1)\n",
        "\n",
        "# Label\n",
        "y = df['price']\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=101)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# fit and transfrom\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# everything has been scaled between 1 and 0\n",
        "print('Max: ',X_train.max())\n",
        "print('Min: ', X_train.min())\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "# input layer\n",
        "model.add(Dense(19,activation='relu'))\n",
        "\n",
        "# hidden layers\n",
        "model.add(Dense(19,activation='relu'))\n",
        "model.add(Dense(19,activation='relu'))\n",
        "model.add(Dense(19,activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam',loss='mse')\n",
        "model.fit(x=X_train,y=y_train.values,\n",
        "          validation_data=(X_test,y_test.values),\n",
        "          batch_size=128,epochs=200)\n",
        "# predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print('MAE: ',mean_absolute_error(y_test,predictions))\n",
        "print('MSE: ',mean_squared_error(y_test,predictions))\n",
        "print('RMSE: ',np.sqrt(mean_squared_error(y_test,predictions)))\n",
        "print('Variance Regression Score: ',explained_variance_score(y_test,predictions))\n",
        "\n",
        "print('\\n\\nDescriptive Statistics:\\n',df['price'].describe())\n",
        "# fueatures of new house\n",
        "single_house = df.drop('price',axis=1).iloc[0]\n",
        "print(f'Features of new house:\\n{single_house}')\n",
        "\n",
        "# reshape the numpy array and scale the features\n",
        "single_house = scaler.transform(single_house.values.reshape(-1, 19))\n",
        "\n",
        "# run the model and get the price prediction\n",
        "print('\\nPrediction Price:',model.predict(single_house)[0,0])\n",
        "\n",
        "# original price\n",
        "print('\\nOriginal Price:',df.iloc[0]['price'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU5U2OaWGpHm",
        "outputId": "2e14c2ee-0b1e-4ff2-8bb9-41f0d766c9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['id' 'date' 'price' 'bedrooms' 'bathrooms' 'sqft_living' 'sqft_lot'\n",
            " 'floors' 'waterfront' 'view' 'condition' 'grade' 'sqft_above'\n",
            " 'sqft_basement' 'yr_built' 'yr_renovated' 'zipcode' 'lat' 'long'\n",
            " 'sqft_living15' 'sqft_lot15']\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21613 entries, 0 to 21612\n",
            "Data columns (total 21 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   id             21613 non-null  int64  \n",
            " 1   date           21613 non-null  object \n",
            " 2   price          21613 non-null  float64\n",
            " 3   bedrooms       21613 non-null  int64  \n",
            " 4   bathrooms      21613 non-null  float64\n",
            " 5   sqft_living    21613 non-null  int64  \n",
            " 6   sqft_lot       21613 non-null  int64  \n",
            " 7   floors         21613 non-null  float64\n",
            " 8   waterfront     21613 non-null  int64  \n",
            " 9   view           21613 non-null  int64  \n",
            " 10  condition      21613 non-null  int64  \n",
            " 11  grade          21613 non-null  int64  \n",
            " 12  sqft_above     21613 non-null  int64  \n",
            " 13  sqft_basement  21613 non-null  int64  \n",
            " 14  yr_built       21613 non-null  int64  \n",
            " 15  yr_renovated   21613 non-null  int64  \n",
            " 16  zipcode        21613 non-null  int64  \n",
            " 17  lat            21613 non-null  float64\n",
            " 18  long           21613 non-null  float64\n",
            " 19  sqft_living15  21613 non-null  int64  \n",
            " 20  sqft_lot15     21613 non-null  int64  \n",
            "dtypes: float64(5), int64(15), object(1)\n",
            "memory usage: 3.5+ MB\n",
            "['price' 'bedrooms' 'bathrooms' 'sqft_living' 'sqft_lot' 'floors'\n",
            " 'waterfront' 'view' 'condition' 'grade' 'sqft_above' 'sqft_basement'\n",
            " 'yr_built' 'yr_renovated' 'lat' 'long' 'sqft_living15' 'sqft_lot15'\n",
            " 'month' 'year']\n",
            "(15129, 19)\n",
            "(6484, 19)\n",
            "(15129,)\n",
            "(6484,)\n",
            "Max:  1.0000000000000002\n",
            "Min:  0.0\n",
            "Epoch 1/200\n",
            "119/119 [==============================] - 2s 4ms/step - loss: 423628111872.0000 - val_loss: 433025417216.0000\n",
            "Epoch 2/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 422835585024.0000 - val_loss: 430239580160.0000\n",
            "Epoch 3/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 411946483712.0000 - val_loss: 404873936896.0000\n",
            "Epoch 4/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 357424136192.0000 - val_loss: 311861477376.0000\n",
            "Epoch 5/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 231118241792.0000 - val_loss: 165522948096.0000\n",
            "Epoch 6/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 120790917120.0000 - val_loss: 107144691712.0000\n",
            "Epoch 7/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 99423797248.0000 - val_loss: 103611613184.0000\n",
            "Epoch 8/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 97778155520.0000 - val_loss: 102181093376.0000\n",
            "Epoch 9/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 96456900608.0000 - val_loss: 100741881856.0000\n",
            "Epoch 10/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 95118950400.0000 - val_loss: 99297853440.0000\n",
            "Epoch 11/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 93745586176.0000 - val_loss: 97769758720.0000\n",
            "Epoch 12/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 92350054400.0000 - val_loss: 96242876416.0000\n",
            "Epoch 13/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 90909597696.0000 - val_loss: 94648336384.0000\n",
            "Epoch 14/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 89390243840.0000 - val_loss: 93030965248.0000\n",
            "Epoch 15/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 87866081280.0000 - val_loss: 91269521408.0000\n",
            "Epoch 16/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 86268928000.0000 - val_loss: 89489661952.0000\n",
            "Epoch 17/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 84582088704.0000 - val_loss: 87654498304.0000\n",
            "Epoch 18/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 82832973824.0000 - val_loss: 85778243584.0000\n",
            "Epoch 19/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 81024417792.0000 - val_loss: 83718905856.0000\n",
            "Epoch 20/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 79111241728.0000 - val_loss: 81826537472.0000\n",
            "Epoch 21/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 77219676160.0000 - val_loss: 79615492096.0000\n",
            "Epoch 22/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 75196596224.0000 - val_loss: 77223698432.0000\n",
            "Epoch 23/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 73081749504.0000 - val_loss: 74947731456.0000\n",
            "Epoch 24/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 71035420672.0000 - val_loss: 72610521088.0000\n",
            "Epoch 25/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 68868186112.0000 - val_loss: 70251864064.0000\n",
            "Epoch 26/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 66727456768.0000 - val_loss: 67901636608.0000\n",
            "Epoch 27/200\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 64630030336.0000 - val_loss: 65649033216.0000\n",
            "Epoch 28/200\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 62622023680.0000 - val_loss: 63475712000.0000\n",
            "Epoch 29/200\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 60791058432.0000 - val_loss: 61491326976.0000\n",
            "Epoch 30/200\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 59094663168.0000 - val_loss: 59661094912.0000\n",
            "Epoch 31/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 57598939136.0000 - val_loss: 58076258304.0000\n",
            "Epoch 32/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 56329760768.0000 - val_loss: 56743800832.0000\n",
            "Epoch 33/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 55234109440.0000 - val_loss: 55586078720.0000\n",
            "Epoch 34/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 54275166208.0000 - val_loss: 54576709632.0000\n",
            "Epoch 35/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 53519015936.0000 - val_loss: 53718274048.0000\n",
            "Epoch 36/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 52767916032.0000 - val_loss: 52986273792.0000\n",
            "Epoch 37/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 52112998400.0000 - val_loss: 52310089728.0000\n",
            "Epoch 38/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 51503828992.0000 - val_loss: 51961020416.0000\n",
            "Epoch 39/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 50996178944.0000 - val_loss: 51156533248.0000\n",
            "Epoch 40/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 50467614720.0000 - val_loss: 50732429312.0000\n",
            "Epoch 41/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 50021445632.0000 - val_loss: 50161029120.0000\n",
            "Epoch 42/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 49584336896.0000 - val_loss: 49707675648.0000\n",
            "Epoch 43/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 49162076160.0000 - val_loss: 49266909184.0000\n",
            "Epoch 44/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 48744099840.0000 - val_loss: 48874409984.0000\n",
            "Epoch 45/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 48368250880.0000 - val_loss: 48441073664.0000\n",
            "Epoch 46/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 47935950848.0000 - val_loss: 48195149824.0000\n",
            "Epoch 47/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 47515549696.0000 - val_loss: 47593586688.0000\n",
            "Epoch 48/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 47100588032.0000 - val_loss: 47180984320.0000\n",
            "Epoch 49/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 46741856256.0000 - val_loss: 46796763136.0000\n",
            "Epoch 50/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 46365474816.0000 - val_loss: 46429687808.0000\n",
            "Epoch 51/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 46044549120.0000 - val_loss: 46141005824.0000\n",
            "Epoch 52/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 45702909952.0000 - val_loss: 45779111936.0000\n",
            "Epoch 53/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 45404844032.0000 - val_loss: 45461368832.0000\n",
            "Epoch 54/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 45108928512.0000 - val_loss: 45196685312.0000\n",
            "Epoch 55/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 44772749312.0000 - val_loss: 44963319808.0000\n",
            "Epoch 56/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 44631990272.0000 - val_loss: 44618182656.0000\n",
            "Epoch 57/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 44315574272.0000 - val_loss: 44376485888.0000\n",
            "Epoch 58/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 44079341568.0000 - val_loss: 44131438592.0000\n",
            "Epoch 59/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 43865530368.0000 - val_loss: 43890212864.0000\n",
            "Epoch 60/200\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 43606228992.0000 - val_loss: 43652706304.0000\n",
            "Epoch 61/200\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 43370475520.0000 - val_loss: 43463102464.0000\n",
            "Epoch 62/200\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 43176628224.0000 - val_loss: 43130163200.0000\n",
            "Epoch 63/200\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 42885808128.0000 - val_loss: 42898341888.0000\n",
            "Epoch 64/200\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 42610827264.0000 - val_loss: 42583343104.0000\n",
            "Epoch 65/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 42343116800.0000 - val_loss: 42453377024.0000\n",
            "Epoch 66/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 42107301888.0000 - val_loss: 42048106496.0000\n",
            "Epoch 67/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 41840697344.0000 - val_loss: 41812119552.0000\n",
            "Epoch 68/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 41589039104.0000 - val_loss: 41605152768.0000\n",
            "Epoch 69/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 41350205440.0000 - val_loss: 41253195776.0000\n",
            "Epoch 70/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 41107193856.0000 - val_loss: 41041317888.0000\n",
            "Epoch 71/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 40924037120.0000 - val_loss: 40724557824.0000\n",
            "Epoch 72/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 40642514944.0000 - val_loss: 40484306944.0000\n",
            "Epoch 73/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 40412512256.0000 - val_loss: 40272093184.0000\n",
            "Epoch 74/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 40220704768.0000 - val_loss: 40025870336.0000\n",
            "Epoch 75/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 40011214848.0000 - val_loss: 39792578560.0000\n",
            "Epoch 76/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 39791075328.0000 - val_loss: 39544680448.0000\n",
            "Epoch 77/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 39563378688.0000 - val_loss: 39309070336.0000\n",
            "Epoch 78/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 39344328704.0000 - val_loss: 39135780864.0000\n",
            "Epoch 79/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 39127375872.0000 - val_loss: 38912163840.0000\n",
            "Epoch 80/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 38949326848.0000 - val_loss: 38821986304.0000\n",
            "Epoch 81/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 38788960256.0000 - val_loss: 38476664832.0000\n",
            "Epoch 82/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 38604644352.0000 - val_loss: 38283767808.0000\n",
            "Epoch 83/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 38401863680.0000 - val_loss: 38156480512.0000\n",
            "Epoch 84/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 38291226624.0000 - val_loss: 37913096192.0000\n",
            "Epoch 85/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 38091190272.0000 - val_loss: 37776486400.0000\n",
            "Epoch 86/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 37983776768.0000 - val_loss: 37620776960.0000\n",
            "Epoch 87/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 37828112384.0000 - val_loss: 37455720448.0000\n",
            "Epoch 88/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 37715881984.0000 - val_loss: 37451210752.0000\n",
            "Epoch 89/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 37587795968.0000 - val_loss: 37183729664.0000\n",
            "Epoch 90/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 37442945024.0000 - val_loss: 37078016000.0000\n",
            "Epoch 91/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 37356748800.0000 - val_loss: 36966977536.0000\n",
            "Epoch 92/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 37264601088.0000 - val_loss: 36845228032.0000\n",
            "Epoch 93/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 37098860544.0000 - val_loss: 36823035904.0000\n",
            "Epoch 94/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 37045080064.0000 - val_loss: 36680364032.0000\n",
            "Epoch 95/200\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 36936945664.0000 - val_loss: 36559876096.0000\n",
            "Epoch 96/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 36871233536.0000 - val_loss: 36453044224.0000\n",
            "Epoch 97/200\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 36783210496.0000 - val_loss: 36389158912.0000\n",
            "Epoch 98/200\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 36689760256.0000 - val_loss: 36274675712.0000\n",
            "Epoch 99/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 36580478976.0000 - val_loss: 36342038528.0000\n",
            "Epoch 100/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 36502011904.0000 - val_loss: 36113088512.0000\n",
            "Epoch 101/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 36454649856.0000 - val_loss: 36018282496.0000\n",
            "Epoch 102/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 36382928896.0000 - val_loss: 36052688896.0000\n",
            "Epoch 103/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 36308586496.0000 - val_loss: 35863592960.0000\n",
            "Epoch 104/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 36249219072.0000 - val_loss: 35806580736.0000\n",
            "Epoch 105/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 36187332608.0000 - val_loss: 35726155776.0000\n",
            "Epoch 106/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 36182753280.0000 - val_loss: 35651268608.0000\n",
            "Epoch 107/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 36023087104.0000 - val_loss: 35592486912.0000\n",
            "Epoch 108/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35937009664.0000 - val_loss: 35551182848.0000\n",
            "Epoch 109/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35881947136.0000 - val_loss: 35451650048.0000\n",
            "Epoch 110/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35858616320.0000 - val_loss: 35381141504.0000\n",
            "Epoch 111/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35771170816.0000 - val_loss: 35326193664.0000\n",
            "Epoch 112/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35707645952.0000 - val_loss: 35245273088.0000\n",
            "Epoch 113/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35635916800.0000 - val_loss: 35224014848.0000\n",
            "Epoch 114/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35604357120.0000 - val_loss: 35127857152.0000\n",
            "Epoch 115/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35541671936.0000 - val_loss: 35086852096.0000\n",
            "Epoch 116/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 35460153344.0000 - val_loss: 34996568064.0000\n",
            "Epoch 117/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35373072384.0000 - val_loss: 35037478912.0000\n",
            "Epoch 118/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35344490496.0000 - val_loss: 34860032000.0000\n",
            "Epoch 119/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35274141696.0000 - val_loss: 34807754752.0000\n",
            "Epoch 120/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35177889792.0000 - val_loss: 34774413312.0000\n",
            "Epoch 121/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35228823552.0000 - val_loss: 34723205120.0000\n",
            "Epoch 122/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35095511040.0000 - val_loss: 34640404480.0000\n",
            "Epoch 123/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35033067520.0000 - val_loss: 34650730496.0000\n",
            "Epoch 124/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34954166272.0000 - val_loss: 34588946432.0000\n",
            "Epoch 125/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34910482432.0000 - val_loss: 34479443968.0000\n",
            "Epoch 126/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34802024448.0000 - val_loss: 34329477120.0000\n",
            "Epoch 127/200\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 34782326784.0000 - val_loss: 34271860736.0000\n",
            "Epoch 128/200\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 34700865536.0000 - val_loss: 34197434368.0000\n",
            "Epoch 129/200\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 34640035840.0000 - val_loss: 34187962368.0000\n",
            "Epoch 130/200\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 34595319808.0000 - val_loss: 34068482048.0000\n",
            "Epoch 131/200\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 34550792192.0000 - val_loss: 34068871168.0000\n",
            "Epoch 132/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34476171264.0000 - val_loss: 33964718080.0000\n",
            "Epoch 133/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34442477568.0000 - val_loss: 33928110080.0000\n",
            "Epoch 134/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34377605120.0000 - val_loss: 33879121920.0000\n",
            "Epoch 135/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34353162240.0000 - val_loss: 33814136832.0000\n",
            "Epoch 136/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34314076160.0000 - val_loss: 33768794112.0000\n",
            "Epoch 137/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34239418368.0000 - val_loss: 33770604544.0000\n",
            "Epoch 138/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34187530240.0000 - val_loss: 33729902592.0000\n",
            "Epoch 139/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34184124416.0000 - val_loss: 33634555904.0000\n",
            "Epoch 140/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34124873728.0000 - val_loss: 33577213952.0000\n",
            "Epoch 141/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34079373312.0000 - val_loss: 33556758528.0000\n",
            "Epoch 142/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34017941504.0000 - val_loss: 33484541952.0000\n",
            "Epoch 143/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34028005376.0000 - val_loss: 33455058944.0000\n",
            "Epoch 144/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33924143104.0000 - val_loss: 33428084736.0000\n",
            "Epoch 145/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33926768640.0000 - val_loss: 33351366656.0000\n",
            "Epoch 146/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33837744128.0000 - val_loss: 33301813248.0000\n",
            "Epoch 147/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33830938624.0000 - val_loss: 33264355328.0000\n",
            "Epoch 148/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 33759453184.0000 - val_loss: 33234655232.0000\n",
            "Epoch 149/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33727348736.0000 - val_loss: 33165459456.0000\n",
            "Epoch 150/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33694926848.0000 - val_loss: 33166499840.0000\n",
            "Epoch 151/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33646540800.0000 - val_loss: 33091102720.0000\n",
            "Epoch 152/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33599508480.0000 - val_loss: 33066283008.0000\n",
            "Epoch 153/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33595918336.0000 - val_loss: 33000265728.0000\n",
            "Epoch 154/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33521618944.0000 - val_loss: 32970680320.0000\n",
            "Epoch 155/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33497198592.0000 - val_loss: 32971632640.0000\n",
            "Epoch 156/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33469708288.0000 - val_loss: 32884617216.0000\n",
            "Epoch 157/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33427576832.0000 - val_loss: 32900907008.0000\n",
            "Epoch 158/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33379950592.0000 - val_loss: 32885958656.0000\n",
            "Epoch 159/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33339629568.0000 - val_loss: 32781031424.0000\n",
            "Epoch 160/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 33374126080.0000 - val_loss: 32739409920.0000\n",
            "Epoch 161/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 33283317760.0000 - val_loss: 32795731968.0000\n",
            "Epoch 162/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 33271119872.0000 - val_loss: 32761573376.0000\n",
            "Epoch 163/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 33253748736.0000 - val_loss: 32702175232.0000\n",
            "Epoch 164/200\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 33224468480.0000 - val_loss: 32628473856.0000\n",
            "Epoch 165/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 33174253568.0000 - val_loss: 32584024064.0000\n",
            "Epoch 166/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33217873920.0000 - val_loss: 32517408768.0000\n",
            "Epoch 167/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33127618560.0000 - val_loss: 32481503232.0000\n",
            "Epoch 168/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33103341568.0000 - val_loss: 32509440000.0000\n",
            "Epoch 169/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33028327424.0000 - val_loss: 32523323392.0000\n",
            "Epoch 170/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33082355712.0000 - val_loss: 32444397568.0000\n",
            "Epoch 171/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33022744576.0000 - val_loss: 32380123136.0000\n",
            "Epoch 172/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 33046306816.0000 - val_loss: 32338083840.0000\n",
            "Epoch 173/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32943497216.0000 - val_loss: 32317079552.0000\n",
            "Epoch 174/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32911298560.0000 - val_loss: 32301158400.0000\n",
            "Epoch 175/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 32913928192.0000 - val_loss: 32292018176.0000\n",
            "Epoch 176/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 32872701952.0000 - val_loss: 32241451008.0000\n",
            "Epoch 177/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 32835694592.0000 - val_loss: 32218800128.0000\n",
            "Epoch 178/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32801906688.0000 - val_loss: 32228612096.0000\n",
            "Epoch 179/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 32785303552.0000 - val_loss: 32174276608.0000\n",
            "Epoch 180/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32766404608.0000 - val_loss: 32177580032.0000\n",
            "Epoch 181/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32741115904.0000 - val_loss: 32114477056.0000\n",
            "Epoch 182/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 32703952896.0000 - val_loss: 32088825856.0000\n",
            "Epoch 183/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32696365056.0000 - val_loss: 32073164800.0000\n",
            "Epoch 184/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32670889984.0000 - val_loss: 32051959808.0000\n",
            "Epoch 185/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32635717632.0000 - val_loss: 32091918336.0000\n",
            "Epoch 186/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32668409856.0000 - val_loss: 32036810752.0000\n",
            "Epoch 187/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32586805248.0000 - val_loss: 31968131072.0000\n",
            "Epoch 188/200\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 32571277312.0000 - val_loss: 32075603968.0000\n",
            "Epoch 189/200\n",
            "119/119 [==============================] - 1s 7ms/step - loss: 32617783296.0000 - val_loss: 31920250880.0000\n",
            "Epoch 190/200\n",
            "119/119 [==============================] - 2s 16ms/step - loss: 32522072064.0000 - val_loss: 31913277440.0000\n",
            "Epoch 191/200\n",
            "119/119 [==============================] - 1s 8ms/step - loss: 32493187072.0000 - val_loss: 31891722240.0000\n",
            "Epoch 192/200\n",
            "119/119 [==============================] - 1s 11ms/step - loss: 32478179328.0000 - val_loss: 31882125312.0000\n",
            "Epoch 193/200\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 32464025600.0000 - val_loss: 31852230656.0000\n",
            "Epoch 194/200\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 32403290112.0000 - val_loss: 31880775680.0000\n",
            "Epoch 195/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32438960128.0000 - val_loss: 31819632640.0000\n",
            "Epoch 196/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32372365312.0000 - val_loss: 31780372480.0000\n",
            "Epoch 197/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32375945216.0000 - val_loss: 31752931328.0000\n",
            "Epoch 198/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32338927616.0000 - val_loss: 31792295936.0000\n",
            "Epoch 199/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32315992064.0000 - val_loss: 31701258240.0000\n",
            "Epoch 200/200\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32281982976.0000 - val_loss: 31677612032.0000\n",
            "203/203 [==============================] - 0s 1ms/step\n",
            "MAE:  109763.81805122465\n",
            "MSE:  31677603754.11353\n",
            "RMSE:  177982.0321103047\n",
            "Variance Regression Score:  0.7741753278324164\n",
            "\n",
            "\n",
            "Descriptive Statistics:\n",
            " count    2.161300e+04\n",
            "mean     5.400881e+05\n",
            "std      3.671272e+05\n",
            "min      7.500000e+04\n",
            "25%      3.219500e+05\n",
            "50%      4.500000e+05\n",
            "75%      6.450000e+05\n",
            "max      7.700000e+06\n",
            "Name: price, dtype: float64\n",
            "Features of new house:\n",
            "bedrooms            3.0000\n",
            "bathrooms           1.0000\n",
            "sqft_living      1180.0000\n",
            "sqft_lot         5650.0000\n",
            "floors              1.0000\n",
            "waterfront          0.0000\n",
            "view                0.0000\n",
            "condition           3.0000\n",
            "grade               7.0000\n",
            "sqft_above       1180.0000\n",
            "sqft_basement       0.0000\n",
            "yr_built         1955.0000\n",
            "yr_renovated        0.0000\n",
            "lat                47.5112\n",
            "long             -122.2570\n",
            "sqft_living15    1340.0000\n",
            "sqft_lot15       5650.0000\n",
            "month              10.0000\n",
            "year             2014.0000\n",
            "Name: 0, dtype: float64\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "Prediction Price: 286406.62\n",
            "\n",
            "Original Price: 221900.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_error=r2_score(y_test, prediction)\n",
        "print('r-squared error', r2_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "1fpbY02tHQvE",
        "outputId": "6ea92f69-78fb-4530-f392-0eff01c6e964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'r2_score' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6b8ef48345d8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr2_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r-squared error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'r2_score' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z3hy91FmI8ct"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}